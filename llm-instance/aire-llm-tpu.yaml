apiVersion: kro.run/v1alpha1
kind: LLMServe
metadata:
  name: aire-deployment-tpu
spec:
  name: vllm-inf-ejv-tpu
  namespace: default
  modelId: deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
  values:
    vllmConfig:
      vllmVersion: e92694b6fe264a85371317295bca6643508034ef
      tensorParallelism: 4
      numSchedulerSteps: 8
      maxModelLen: 8192
    deployment:
      computeClass: tpu-inference-autoprov
      replicas: 1
      accelerator: 
        google.com/tpu: "4"
    hpa:
      minReplicas: 1
      maxReplicas: 10